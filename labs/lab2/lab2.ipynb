{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSGA 1018 - Lab 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please submit the code and a pdf of the output.\n",
    "\n",
    "Your work will be evaluated based on the code and plots. You don't need to write down your answers to these questions in the text blocks. Everything that will be graded is indicated by the \"TODO\".\n",
    "\n",
    "Due: 2021-10-05 23:59pm (Next Tuesday midnight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.tsa.stattools import acf, ccf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.graphics import utils\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from statsmodels.graphics.api import qqplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply AR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will fit an AR(p) model to the SunActivity data, which denotes the number of sunspots for each year.\n",
    "\n",
    "We will determine p, fit the model, compute the roots and the lag 0 to p components of the ACF.\n",
    "\n",
    "Wikipedia for sunspots: https://en.wikipedia.org/wiki/Sunspot\n",
    "\n",
    "The code in this section is selected from the tutorial specified in the reference section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dta = sm.datasets.sunspots.load_pandas().data\n",
    "dta.index = pd.Index(sm.tsa.datetools.dates_from_range('1700', '2008'))\n",
    "del dta[\"YEAR\"]\n",
    "dta.plot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACF & PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(dta.values.squeeze(), lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(dta, lags=40, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit AR Model of order p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: chose p appropriately\n",
    "p = \n",
    "\n",
    "arma_mod = sm.tsa.ARMA(dta, (p,0)).fit(disp=False)\n",
    "print(arma_mod.params)\n",
    "\n",
    "# TODO: predict ACF of model at lag 0, 1, ..., p\n",
    "rho = np.zeros(p+1)\n",
    "    \n",
    "# TODO: compute roots\n",
    "roots = np.zeros(2)\n",
    "\n",
    "print('roots: ', roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: try to predict further into the future by increasing tsteps\n",
    "tsteps=\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax = dta.ix['1900':].plot(ax=ax)\n",
    "T = np.arange(1930, 2010, tsteps)\n",
    "for tt in range(len(T)-1):\n",
    "    fig = arma_mod.plot_predict(np.str(T[tt]), np.str(T[tt+1]), dynamic=True, ax=ax, plot_insample=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sunspots = arma_mod.predict('1950', '2012', dynamic=True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(dta.values.squeeze(), lags=40, ax=ax1)\n",
    "ax1.plot(np.arange(p+1), rho, 'xr', label='prediction')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement AR model from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section I: Implementing the AR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the negative log-likelihood function takes as input the parameter values and returns the negative log probability\n",
    "of the observed data, under the assumption that those were the parameters used to generate the data.\n",
    "\n",
    "For an AR(p) model, we have:\n",
    "\n",
    "$$ NLL(\\phi_1, \\phi_2, \\ldots, \\phi_p, \\sigma ~; x_1, x_2, \\ldots, x_n) = \\sum_{t=p+1}^n \\left( \\log \\left( \\sigma \\sqrt{2 \\pi} \\right) + \\frac{1}{2} \\cdot \\left( \\frac{x_t - \\left( \\sum\\limits_{i=1}^p \\phi_i x_{t-i} \\right)}{\\sigma} \\right)^2 \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: We use Nelder-Mead Algorithm to find the minimum of the loss. Check this link if you're interested (https://machinelearningmastery.com/how-to-use-nelder-mead-optimization-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARModel:\n",
    "    \"\"\"Class that implements an ARMA Model. Its functions are as follows:\n",
    "    1. Maximum Likelihood estimation of parameters\n",
    "    2. Inference/prediction of future states\n",
    "    3. Data simulation\n",
    "    \"\"\"\n",
    "    def __init__(self, p, data, p_params = None, sigma = None):\n",
    "        \"\"\"Initialize the network state\n",
    "        @param p: the number of time steps to include in the AR process\n",
    "        @param p_params: the initialization for the AR parameters\n",
    "        \"\"\"\n",
    "        if (p_params is None):\n",
    "            p_params = np.zeros(p)\n",
    "        if (sigma is None):\n",
    "            sigma = 1\n",
    "            \n",
    "        assert p == len(p_params)\n",
    "        \n",
    "        #assign parameter values\n",
    "        self.p = p\n",
    "        self.p_params = p_params\n",
    "        self.sigma = sigma\n",
    "        #store the data within the object\n",
    "        self.data = data\n",
    "    \n",
    "    def loss(self, params):\n",
    "        \"\"\"\n",
    "        params: array of parameters, elements 0:p = p_params, element p = sigma\n",
    "        returns: loss\n",
    "        \"\"\"\n",
    "        assert len(params) == self.p + 1\n",
    "        N = self.data.shape[0]\n",
    "        p_params = params[0:self.p]\n",
    "        sigma = params[self.p]\n",
    "        loss = 0\n",
    "        \n",
    "        #TODO: calculate the NLL of the data for the purposes of optimization and store it in loss\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def fit(self):\n",
    "        # Minimize the loss function, given the dataset\n",
    "        params = np.concatenate((self.p_params, np.array([self.sigma])))\n",
    "        res = minimize(self.loss, params, method='nelder-mead',\n",
    "               options={'xatol': 1e-8, 'disp': True})\n",
    "        self.p_params = res.x[0:self.p]\n",
    "        self.sigma = res.x[self.p]\n",
    "        \n",
    "    def predict(self,data, N):\n",
    "        \"\"\"Method that predicts N timesteps in the future given input data\n",
    "        @params data: p data points used to form the prediction\n",
    "        @params N: number of time steps to predict in the future\n",
    "        \n",
    "        returns:\n",
    "        prediction: predicted future value\n",
    "        conf: variance of the estimated future value\n",
    "        \"\"\"\n",
    "        assert len(data) == self.p\n",
    "        predction = np.zeros(N)\n",
    "        conf = np.zeros(N)\n",
    "        \n",
    "        #TODO: predict N time steps in advance, given an input. \n",
    "        #The inference can be specific to your choice of p, no need to worry about general inference here\n",
    "\n",
    "        return prediction, conf\n",
    "        \n",
    "    def simulate(self,N):\n",
    "        \"\"\"Method that stimulates data given the p_params and q_params\n",
    "        @param N: number of datapoints to simulate\n",
    "        returns: N sampled datapoints\n",
    "        \"\"\"\n",
    "        transient = 100 # length of time to run the simulation to wash out initial conditions\n",
    "        w_t = self.sigma * np.random.normal(size = (N + transient,))\n",
    "        x_t = np.zeros(N + transient)\n",
    "        \n",
    "        # TODO: generate data x_t given the parameters and white noise w_t\n",
    "        \n",
    "        return x_t[transient::] #discard the transient when returning simulated data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section II: Fitting the AR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load some data from an unknown source, look at its ACF and PACF\n",
    "plots to determine an appropriate AR(p) order, and fit the AR(p) model to the data to determine\n",
    "the coefficients of the AR model as well as the standard deviation of the driving white noise process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"lab_2_data.npy\")\n",
    "\n",
    "#plot the acf of the data\n",
    "lag = 20\n",
    "plt.plot(data)\n",
    "plot_acf(x=data, lags=lag, title=\"ACF w_t\")\n",
    "plt.show()\n",
    "\n",
    "#plot the pacf of the data\n",
    "plt.figure()\n",
    "sm.graphics.tsa.plot_pacf(data, lags=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "p = 0 #TODO: choose a 'p' value\n",
    "data_fitter = ARModel(p, data, p_params = np.array([]), sigma = 0.5) # set p_params and sigma to an educated guess for parameter values\n",
    "data_fitter.fit()\n",
    "print('lambda = ' + str(data_fitter.p_params))\n",
    "print('sigma = ' + str(data_fitter.sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section III: Simulating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use our fitted model to simulate a run of the AR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate 1000 samples from the fit model\n",
    "data_2 = data_fitter.simulate(1000)\n",
    "\n",
    "#Compare the ACF from the fit model to the data ACF\n",
    "lag = 20\n",
    "\n",
    "plot_acf(x=data, lags=lag, title=\"ACF data\")\n",
    "plot_acf(x=data_2, lags=lag, title=\"ACF data_2\")\n",
    "plt.show()\n",
    "\n",
    "#Compare the PACF from the fit model to the data ACF\n",
    "plt.figure()\n",
    "sm.graphics.tsa.plot_pacf(data, lags=20)\n",
    "plt.title('PACF Data')\n",
    "sm.graphics.tsa.plot_pacf(data_2, lags=20)\n",
    "plt.title('PACF Data 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section IV: Using the AR Model for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use some of the provided data as a starting point and predict the next 20 values\n",
    "based on our AR model's fitted parameters. This will be repeated for each of various starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each of the given data points, generate predictions 20 time steps into the future\n",
    "\n",
    "data_prediction = data[0:100:25]\n",
    "predictions = np.zeros((len(data_prediction), 20))\n",
    "mse = np.zeros((len(data_prediction), 20))\n",
    "for ii in range(0, len(data_prediction)):\n",
    "    for jj in range(0,20):\n",
    "        #for each data point, predict for each of 20 time steps\n",
    "        predictions[ii,jj], mse[ii,jj] = data_fitter.predict(data_prediction[[ii]],jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the MSE bars of the estimate\n",
    "plt.figure()\n",
    "for ii in range(0, len(data_prediction)):\n",
    "    plt.errorbar(np.arange(0,20), predictions[ii,:], yerr = mse[ii,:])\n",
    "plt.legend(data_prediction)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
